#!/usr/bin/env python3
"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π RAG —Å–µ—Ä–≤–µ—Ä —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π IDE –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ñ–∞–π–ª –∏ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥
"""

import yaml
import time
import logging
from typing import Optional, List, Dict, Any
from pathlib import Path

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
import chromadb
from sentence_transformers import SentenceTransformer
import requests

# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
def load_config(config_path: str = "config.yaml") -> Dict[str, Any]:
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except FileNotFoundError:
        raise Exception(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ñ–∞–π–ª {config_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
CONFIG = load_config()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=getattr(logging, CONFIG.get('logging', {}).get('level', 'INFO')),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
def init_database():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ChromaDB"""
    db_config = CONFIG['database']
    client = chromadb.PersistentClient(path=db_config['path'])
    
    try:
        collection = client.get_collection(db_config['collection_name'])
        logger.info(f"–ü–æ–¥–∫–ª—é—á–∏–ª–∏—Å—å –∫ –∫–æ–ª–ª–µ–∫—Ü–∏–∏. –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {collection.count()}")
        return collection
    except Exception as e:
        logger.warning(f"–ö–æ–ª–ª–µ–∫—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {e}")
        logger.info("–°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é...")
        try:
            collection = client.create_collection(db_config['collection_name'])
            logger.info("‚úÖ –°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è")
            return collection
        except Exception as create_error:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {create_error}")
            raise HTTPException(status_code=500, detail="–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")

def init_embedder():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
    model_name = CONFIG['embeddings']['model']
    logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {model_name}")
    return SentenceTransformer(model_name)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
collection = init_database()
embedder = init_embedder()

# FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = FastAPI(
    title="RAG Assistant API",
    description="–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π RAG –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–æ–≤",
    version="2.0.0"
)

# CORS –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
server_config = CONFIG.get('server', {})
cors_origins = server_config.get('cors_origins', ["*"])

app.add_middleware(
    CORSMiddleware,
    allow_origins=cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
class QueryRequest(BaseModel):
    question: str = Field(..., description="–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
    framework: Optional[str] = Field(None, description="–§–∏–ª—å—Ç—Ä –ø–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫—É")
    max_results: int = Field(5, ge=1, le=20, description="–ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    context: Optional[str] = Field(None, description="–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç")
    model: Optional[str] = Field(None, description="–ú–æ–¥–µ–ª—å LLM (qwen –∏–ª–∏ deepseek)")

class IDEQueryRequest(BaseModel):
    question: str = Field(..., description="–í–æ–ø—Ä–æ—Å –æ—Ç IDE")
    file_path: Optional[str] = Field(None, description="–ü—É—Ç—å –∫ —Ç–µ–∫—É—â–µ–º—É —Ñ–∞–π–ª—É")
    file_content: Optional[str] = Field(None, description="–°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞")
    cursor_position: Optional[Dict[str, int]] = Field(None, description="–ü–æ–∑–∏—Ü–∏—è –∫—É—Ä—Å–æ—Ä–∞")
    framework: Optional[str] = Field(None, description="–ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫")
    quick_mode: bool = Field(True, description="–ë—ã—Å—Ç—Ä—ã–π —Ä–µ–∂–∏–º –¥–ª—è –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è")

class QueryResponse(BaseModel):
    answer: str
    sources: List[Dict[str, str]]
    total_docs: int
    response_time: float
    framework_detected: Optional[str] = None

# –ö—ç—à –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
cache = {}
cache_config = CONFIG.get('cache', {})

# –£—Ç–∏–ª–∏—Ç—ã
def detect_framework_from_context(file_path: str = None, file_content: str = None) -> Optional[str]:
    """–ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É —Ñ–∞–π–ª–∞"""
    if file_path:
        path_lower = file_path.lower()
        if any(x in path_lower for x in ['.vue', 'vue.js', 'vue.config']):
            return 'vue'
        elif any(x in path_lower for x in ['artisan', 'composer.json', 'laravel']):
            return 'laravel'
    
    if file_content:
        content_lower = file_content.lower()
        if any(x in content_lower for x in ['<template>', 'vue', 'composition api']):
            return 'vue'
        elif any(x in content_lower for x in ['eloquent', 'blade', 'artisan', 'laravel']):
            return 'laravel'
    
    return None

def get_cache_key(question: str, framework: str = None) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–∞ –∫—ç—à–∞"""
    return f"{question}:{framework or 'all'}"

def get_cached_response(cache_key: str) -> Optional[Dict]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –∏–∑ –∫—ç—à–∞"""
    if not cache_config.get('enabled', True):
        return None
    
    if cache_key in cache:
        cached_data = cache[cache_key]
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º TTL
        if time.time() - cached_data['timestamp'] < cache_config.get('ttl', 3600):
            return cached_data['data']
        else:
            del cache[cache_key]
    
    return None

def set_cached_response(cache_key: str, response: Dict):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –≤ –∫—ç—à"""
    if not cache_config.get('enabled', True):
        return
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞
    max_size = cache_config.get('max_size', 1000)
    if len(cache) >= max_size:
        # –£–¥–∞–ª—è–µ–º —Å–∞–º—ã–µ —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏
        oldest_key = min(cache.keys(), key=lambda k: cache[k]['timestamp'])
        del cache[oldest_key]
    
    cache[cache_key] = {
        'data': response,
        'timestamp': time.time()
    }

async def query_llm(prompt: str, model_name: str = None, quick_mode: bool = False) -> str:
    """–ó–∞–ø—Ä–æ—Å –∫ LLM"""
    llm_config = CONFIG['llm']
    
    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    model_key = model_name or llm_config.get('default_model', 'qwen')
    if model_key not in llm_config['models']:
        model_key = llm_config['default_model']
    
    model_config = llm_config['models'][model_key]
    
    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –º–æ–¥–µ–ª–∏
    if model_key == 'qwen':  # LM Studio API
        payload = {
            "model": model_config['model_name'],
            "prompt": prompt,
            "max_tokens": 200 if quick_mode else model_config['max_tokens'],
            "temperature": model_config['temperature']
        }
        
        try:
            response = requests.post(
                model_config['api_url'], 
                json=payload,
                timeout=CONFIG.get('ide', {}).get('quick_response_timeout', 2.0) if quick_mode else 60
            )
            
            if response.status_code != 200:
                raise Exception(f"LLM API error: {response.status_code}")
            
            return response.json()["choices"][0]["text"].strip()
        
        except requests.exceptions.Timeout:
            if quick_mode:
                return "–ë—ã—Å—Ç—Ä—ã–π –æ—Ç–≤–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –±–µ–∑ quick_mode."
            raise
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM: {e}")
            raise HTTPException(status_code=500, detail=f"LLM —Å–µ—Ä–≤–∏—Å {model_key} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
    
    elif model_key == 'deepseek':  # Ollama API
        payload = {
            "model": model_config['model_name'],
            "prompt": prompt,
            "max_tokens": 200 if quick_mode else model_config['max_tokens'],
            "temperature": model_config['temperature'],
            "stream": False
        }
        
        try:
            response = requests.post(
                model_config['api_url'], 
                json=payload,
                timeout=CONFIG.get('ide', {}).get('quick_response_timeout', 2.0) if quick_mode else 60
            )
            
            if response.status_code != 200:
                raise Exception(f"Ollama API error: {response.status_code}")
            
            return response.json()["response"].strip()
        
        except requests.exceptions.Timeout:
            if quick_mode:
                return "–ë—ã—Å—Ç—Ä—ã–π –æ—Ç–≤–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –±–µ–∑ quick_mode."
            raise
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ Ollama: {e}")
            raise HTTPException(status_code=500, detail=f"Ollama —Å–µ—Ä–≤–∏—Å {model_key} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
    
    else:
        raise HTTPException(status_code=400, detail=f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å: {model_key}")

# API endpoints
@app.get("/")
async def root():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ API"""
    frameworks = {name: config['name'] for name, config in CONFIG['frameworks'].items() 
                 if config.get('enabled', True)}
    
    return {
        "message": "üöÄ RAG Assistant API v2.0",
        "description": "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π RAG –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π IDE",
        "frameworks": frameworks,
        "total_docs": collection.count(),
        "endpoints": {
            "/ask": "POST - –û–±—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å",
            "/ide/ask": "POST - –ó–∞–ø—Ä–æ—Å –æ—Ç IDE",
            "/stats": "GET - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞",
            "/frameworks": "GET - –°–ø–∏—Å–æ–∫ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–æ–≤"
        }
    }

@app.get("/frameworks")
async def get_frameworks():
    """–°–ø–∏—Å–æ–∫ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–æ–≤"""
    frameworks = {}
    for name, config in CONFIG['frameworks'].items():
        if config.get('enabled', True):
            frameworks[name] = {
                "name": config['name'],
                "description": config.get('description', ''),
                "type": config.get('type', 'markdown')
            }
    return frameworks

@app.get("/models")
async def get_models():
    """–°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    models = {}
    for name, config in CONFIG['llm']['models'].items():
        models[name] = {
            "name": config['model_name'],
            "max_tokens": config['max_tokens'],
            "temperature": config['temperature']
        }
    
    return {
        "models": models,
        "default": CONFIG['llm'].get('default_model', 'qwen')
    }

@app.get("/stats")
async def get_stats():
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    total_docs = collection.count()
    
    # –ü–æ–ª—É—á–∞–µ–º –í–°–ï –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è —Ç–æ—á–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    if total_docs > 0:
        all_results = collection.get(limit=total_docs)
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –ø–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞–º
        framework_counts = {}
        for metadata in all_results["metadatas"]:
            framework = metadata.get("framework", "unknown").upper()
            framework_counts[framework] = framework_counts.get(framework, 0) + 1
    else:
        framework_counts = {}
    
    return {
        "total_documents": total_docs,
        "frameworks": framework_counts,
        "cache_size": len(cache) if cache_config.get('enabled') else 0
    }

@app.post("/ask", response_model=QueryResponse)
async def ask_question(data: QueryRequest):
    """–û—Å–Ω–æ–≤–Ω–æ–π endpoint –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤"""
    start_time = time.time()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
    cache_key = get_cache_key(data.question, data.framework)
    cached_response = get_cached_response(cache_key)
    if cached_response:
        cached_response['response_time'] = time.time() - start_time
        return QueryResponse(**cached_response)
    
    # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –ø–æ–∏—Å–∫–∞
    query_embedding = embedder.encode(data.question).tolist()
    
    # –§–∏–ª—å—Ç—Ä –ø–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫—É
    where_filter = None
    if data.framework:
        where_filter = {"framework": data.framework.lower()}
    
    # –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=data.max_results,
        where=where_filter
    )
    
    documents = results["documents"][0]
    metadatas = results["metadatas"][0]
    
    if not documents:
        raise HTTPException(status_code=404, detail="–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
    frameworks = [meta.get("framework", "unknown") for meta in metadatas]
    main_framework = max(set(frameworks), key=frameworks.count) if frameworks else "unknown"
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    context_parts = []
    for doc, meta in zip(documents, metadatas):
        framework = meta.get("framework", "unknown").upper()
        source = meta.get("source", "unknown")
        heading = meta.get("heading", "")
        context_parts.append(f"[{framework}] {source} - {heading}\n{doc}")
    
    context = "\n\n".join(context_parts)
    
    # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    framework_title = main_framework.title() if main_framework != "unknown" else "Web Development"
    
    prompt = f"""[{framework_title} Documentation Context]
{context}

[User Question]
{data.question}

[Additional Context]
{data.context or "–ù–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"}

[Instructions]
- Answer based on the provided documentation context
- If the question relates to {framework_title}, prioritize {framework_title}-specific information
- Provide practical, actionable advice with code examples when relevant
- Be concise but comprehensive

[Answer]"""
    
    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç LLM
    answer = await query_llm(prompt, data.model)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
    response_data = {
        "answer": answer,
        "sources": [
            {
                "framework": meta.get("framework", "unknown").upper(),
                "source": meta.get("source", "unknown"),
                "heading": meta.get("heading", "")
            }
            for meta in metadatas
        ],
        "total_docs": len(documents),
        "response_time": time.time() - start_time,
        "framework_detected": main_framework
    }
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
    set_cached_response(cache_key, response_data)
    
    return QueryResponse(**response_data)

@app.post("/ide/ask", response_model=QueryResponse)
async def ide_ask_question(data: IDEQueryRequest):
    """–°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π endpoint –¥–ª—è IDE –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏"""
    start_time = time.time()
    
    # –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞
    detected_framework = data.framework or detect_framework_from_context(
        data.file_path, data.file_content
    )
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è IDE
    ide_context = []
    if data.file_path:
        ide_context.append(f"–¢–µ–∫—É—â–∏–π —Ñ–∞–π–ª: {data.file_path}")
    if data.cursor_position:
        ide_context.append(f"–ü–æ–∑–∏—Ü–∏—è –∫—É—Ä—Å–æ—Ä–∞: —Å—Ç—Ä–æ–∫–∞ {data.cursor_position.get('line', 0)}")
    
    # –°–æ–∑–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å
    query_request = QueryRequest(
        question=data.question,
        framework=detected_framework,
        max_results=3 if data.quick_mode else 5,
        context="\n".join(ide_context) if ide_context else None
    )
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –ª–æ–≥–∏–∫—É
    response = await ask_question(query_request)
    
    # response —É–∂–µ —è–≤–ª—è–µ—Ç—Å—è –æ–±—ä–µ–∫—Ç–æ–º QueryResponse
    # –ü—Ä–æ—Å—Ç–æ –æ–±–Ω–æ–≤–ª—è–µ–º framework_detected –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if detected_framework:
        response.framework_detected = detected_framework
    
    return response

@app.delete("/cache")
async def clear_cache():
    """–û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞"""
    cache.clear()
    return {"message": "–ö—ç—à –æ—á–∏—â–µ–Ω", "timestamp": time.time()}

# –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞
if __name__ == "__main__":
    import uvicorn
    
    server_config = CONFIG.get('server', {})
    host = server_config.get('host', '0.0.0.0')
    port = server_config.get('port', 8000)
    
    print(f"üöÄ –ó–∞–ø—É—Å–∫ RAG —Å–µ—Ä–≤–µ—Ä–∞ –Ω–∞ {host}:{port}")
    print(f"üìö –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑–µ: {collection.count()}")
    
    uvicorn.run(app, host=host, port=port)
